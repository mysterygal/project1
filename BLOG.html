BLOG
Telecom Churn PRediction


#Include the links of all the websites. 

Hi folks,Finally I am writing my first blogpost after giving so  much thought about which subject to write about,I decided to go with a full Machine learning project I recently did.
I will share the zest of all the things that I tried and what worked for me best.
I hope it will help you in developing the approach to solve similar problems.

In this blog I have tried to answer  the following questions 

1)What is  introduction to real World dataset?

2)How to convert the buisness problem to technical problem ?

3)How to decide the evaluation metrics?

4)How to decide which model is good ?

5)What can be further done to improve our model?




A)Buisness PRoblem
Telecom churn Prediction in South Asia

In recent past,due to many emergeing telecom beasts the competetion in telecom sector in south asia has increased.Now,Due to this customers can choose from a wide range of providers and are easy to get churned.Churned customer here refers the one who is not using the sevices and thus not contributing to any revenue for the company.

Thus it is important to keep the cusotomers satisfied with the services.Also according to the paper [1],#https://www.atlantis-press.com/journals/ijcis/25885044/view

It is less costly to retain the customer than to acquire new cusomer and it is essential for a company to focus on providing offers and good services.
I have taken this dataset from the Kaggle [2]



Q)What are real world buisness objective and Constraints?

PROBLEM DEFINATION:
--To predict the customers who are going to churn.


a.The cost of a mis-classification,especially false negetives can be very high because if a customer is going to churn and is predicted opposite,it will directly impact on loss of revenue.

b.Probablistic output may help to determine the actual chances of getting churned hence output probablities are important to calculate.

c.As this model does not concern with immediate input and output,time latency of prediction is not much of a concern.


d.Interpretability is partially important because we should know which factors contribute to the customer satisfaction.But it wont help us directly.





B)Data:
IF you understand the data,you have won 90% of the war and which also means it is the difficult task.Now,here understanding the data means understanding the domain from where the data have been generated.This is where our curiosity comes into play.As we know Data speaks for itself and we will ask ourselves some questions in order to understand this data.

Q)What is domain of Data:

It comes from Telecom sector.4 months of data of 100 thousand users is been provided.Size of data is nearly 172 MB.For each user there are 226 different features.

Q)What does each feature actully mean?

1)Mobile Number of each user

2)Circle Id: 109 only one region's data is there

3)Dates: Various recharge dates are available month wise.

4)ARPU is Average Revenue Per user

5)MOU:Time in minutes of user

6)Roming,ISD,STD,Local ,Special and other Recharge information

7)Recharge amounts of various months,types,Max amount and Last DAy Recharge Amount etc.

8)Data usage information of different types like Night pack,FB etc.

9)Age of Network


EDA:

IDENTIFYING CHURN:
Those cutomers who have not recharged in the last month can be tagged as churned as they have high possibility of churning.The data is available for 4 months 6,7,8 and 9 so the 9th month is assumed as last month.
Well we need to ask one more question here.

Why Minutes total are used for Churn calculation and not dates of previous recharge? 

Because recharge can be done for even more than one month and hence it wont reflect in the given data.But Minutes of usage relflects on the actual utilization of card.

[PASTE THE IMAGE OF churn]

We can see that the distribution of churned people are significantly different.For high Age of network,the churn rate is less and the age of network is large,churn rate is more.Especially,below 1000 days,the churn rate is higher.Which can be inferred as customers who have joined new,are more prone to churn.


[paste the box plot]

We can see that there is no significant change in average revenue of subsequent months w.r.t churn.
[paste the image]


Feature Engineering
Adding New features for analysis
As given is raw data and we can come up with better features suitable for analysis.
One of them is the date feature.The dates are there which can be used to deduce the difference between the subsequent recharges.

Also,after doing analysis of Total Incoming call minutes feature,we can conclude that it is sum of all incoming MOUs.So,we can assume directly that if this is zero,then other incoming columns will automatically be zero. So,it can be imputed with zeros.Similarly,for total outgoing call minutes with null value,all outgoing call columns can be imputed by zero.

Also,there are 2 more features related to mobile number
1)Number of unique digits in mobile number
2)Starting 3 digits of a mobile number
As sometimes some numbers are acquired bhy user purely on the basis of digits.

FILTERING CUSTOMERS:
[plot]
As in the plot we can see that the percentile of distribution of total recharge amount takes an exponentialy increasing turn when moving forward.So those customers are filtered out which contribute more than 60% for the revenue.39982 are total customers which are filtered out.


MISSING VALUE ANALYSIS:

[ADD plot]
So,there are total 166 columns with some amount of missing data and nearly 42 columns have more than 74% of missing data.

Adding new columns which will indicate the presence and absence of a missing value helps in this scenario.

Imputing MISSING VALUES  :Using mean and median imputation method,all the missing values are imputed.
But here is a catch,that this is done only after train test splitting.


DATA VISUALIZATION AND CORRELATION
[second correlation plot]

Modeling:
This is most esiest part of Machine learning in terms of coding but you have to know basic intution about each type of model and the mathematical working behind it which can give you clear idea of what is happening with the given data.
As our problem defination is about predictive modelling and the task at hand is of classification,we will start with simple logistic regression.
[pretty table image]
2)Balencing dataset
3)PCA
4)Random forest
5)XGBOOST







.
.
.
.
.
.
.
.
.
.

I have tried my best to arrive at First cut and industry acceptable solution in very less amount of time.There of further feature analysis and deployment which is can be topic of next blog.
I am going to end this blog on the note of thanking all the people who are involved in motivating me for writing especially my parents and siblings ;-)

RESUME:


Implement TFIDF vectorizer
knn randomsearchcv 
performence metric
naive bayes on Donors Choose dataset
sgd classifier lo
Behaviour of linear models
Doners choose dataset-ALl models 
Clustering on Graph DAtaset
REcommendation shstem and trucncated svd sgd algo predict ratingas of 
<Microsoft malware detection
Facebook friend recommendation--??
SQL basic and medium queries

-----------------------------------
===================================

DEEP LEARNING:---

Satellite image classification of classes-----

Backpropogation working and gradient checking----

Working with Callbacks-----

Transfer Learning----

Self Cases-----

Document Classification with CNN----

LSTM on Doners Choose-----

CNN on CIFR-----

nlp with transfer learning-----

Spoken digit recognition-------

#Resume Building:---














